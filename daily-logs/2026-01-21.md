# 2026-01-21

## 추가 정리
- Monologue 호출부와 API 시그니처 불일치 수정으로 빌드/런타임 오류 방지
- LogConversationExtended가 NormalizeActionType를 타도록 수정해 로그 분류 일관성 확보
- `Assets/_Project/Scripts/AI` 추적 추가로 다른 환경 빌드 실패 위험 제거

## 오늘 목표
- Control 기반 프롬프트/응답 파이프라인 정리 및 적용
- DevTools AI 튜닝/벤치마크 기능 확장
- LoRA 학습용 로그/데이터셋 흐름 준비

## 변경 요약
- Ollama 연동을 Control 레이어 중심으로 재구성하고 응답 후처리/재시도/폴백을 통합
- 대화 로그에 Control JSON, 모델명, 원본 응답 등 LoRA 학습용 필드 확장
- DevTools에 모델 관리, 데이터셋 생성/내보내기, 벤치마크 실행 로직 추가
- 테스트셋(jsonl) 준비 및 모델 벤치마크 도구 기반 마련

## 변경 파일(핵심)
- `Assets/_Project/Scripts/API/OllamaAPIManager.cs`
- `Assets/_Project/Scripts/Managers/InteractionLogger.cs`
- `Tools/CatDevTools/ViewModels/MainViewModel.cs`
- `Tools/CatDevTools/Services/OllamaService.cs`
- `Tools/CatDevTools/Services/BenchmarkRunner.cs`
- `Tools/Benchmark/benchmark_models.py`
- `Tools/20260121/testset.jsonl`

## 테스트
- [ ] Unity Play 10초
- [ ] Console Error 0
- 결과:

---

## 학습 노트 (개발 스킬 기록)

### 1. 구현 영역
- **어디를**: LLM 프롬프트 생성/후처리 파이프라인, DevTools AI 튜닝/벤치마크, 로그 확장
- **무엇을**: ControlBuilder → PromptBuilder → ResponseProcessor 흐름 적용, 모델 관리/테스트셋 기반 벤치마크 구현

### 2. 객체지향 개념
- **사용된 OOP 원칙**:
  - 캡슐화: 응답 후처리/폴백을 `ResponseProcessor`로 분리
  - 상속: `MonoBehaviour` 기반 매니저 유지
  - 다형성: 서비스 계층으로 기능 분리(`OllamaService`, `BenchmarkRunner`)
  - 추상화: DevTools 기능을 ViewModel에서 통합 추상화

- **디자인 패턴**: 싱글톤(OllamaAPIManager, InteractionLogger), 서비스 레이어 분리

### 3. 메모리 & 성능 고려사항
- **메모리 할당**:
  - JSON 직렬화는 필요 시에만 수행(로그 확장 시)
- **가비지 컬렉션 최적화**:
  - 재시도 루프 최소화, 결과가 유효하면 즉시 종료
- **성능 최적화**:
  - 응답 길이 제한으로 대화 처리 시간 및 UI 부담 감소

### 4. C# 문법 & 기능
- **새로 사용한 문법**:
  - `event` 기반 모델 변경 알림
  - `async/await` 기반 Ollama 통신/벤치마크 실행
- **타입 시스템**:
  - 기록 확장 필드에 `int?` 사용(미평가 상태 표현)
- **예외 처리**:
  - API 호출 실패 시 폴백 응답 경로 정리

### 5. Unity 특화 지식
- **Unity API**:
  - `UnityWebRequest` 기반 LLM 호출
- **Unity 베스트 프랙티스**:
  - 필요 시만 로그 출력(프롬프트/Control JSON)
- **에디터 연동**:
  - DevTools와의 모델 변경 연동 포인트 확보

### 6. CS(컴퓨터과학) 개념
- **자료구조**: JSONL 기반 데이터셋 구성
- **알고리즘**: 간단한 키워드 기반 평가/스코어링
- **비동기/동시성**: 벤치마크 작업 진행률 스트리밍
- **네트워크/파일 I/O**: Ollama API, 로그/데이터셋 파일 읽기/쓰기

### 7. 실수 & 해결
- **발생한 버그**: 해당 없음
- **원인 분석**: -
- **해결 방법**: -
- **재발 방지**: -

---

## 배운 점 / 다음에 반영할 것
- Control JSON을 중심으로 파이프라인을 묶으면 튜닝/테스트 자동화가 쉬워짐
- DevTools에서 모델 관리/벤치마크를 묶어 운용하면 반복 검증이 빨라짐

## 내일 할 일(1~3개)
- Unity 쪽 모델 변경 이벤트와 DevTools 연동 구현
- 테스트셋/데이터셋 생성 흐름에 검증 및 에러 메시지 보강
- 벤치마크 결과 차트/랭킹 출력 정리 및 저장 옵션 추가

---

## LoRA 학습 계획 (GPT 의견 + Claude 검토)

### GPT 의견 검토

| GPT 의견 | Claude 판단 | 비고 |
|---------|-------------|------|
| LoRA가 정답, SFT는 학습 방식 | ✅ 동의 | Full Fine-tuning 대비 효율적 |
| Unsloth 추천 (Python) | ✅ 동의 | Ollama보다 품질 좋음 |
| 데이터 1800~6000개가 적당 | ⚠️ 부분 동의 | 처음엔 500~1000개로 시작해도 됨 |
| ActionLanguage 강제 포함 | ✅ 강력 동의 | 이게 없으면 고양이다움 안 나옴 |
| TrustLow에 애교 금지 | ✅ 동의 | 데이터 일관성 중요 |
| 학습 후 벤치마크 비교 | ✅ 동의 | 이미 준비됨 |

### 현재 프로젝트 강점

```
✅ 벤치마크 시스템 (Basic 25점 + CatLikenessScore 100점)
✅ 상세 Export (케이스×모델별 분석)
✅ ScoreReasons 분리 (User/Debug)
✅ 키워드 기반 채점 시스템
→ "학습 → 평가 → 비교" 루프 완성됨
```

### 학습 목표 정리

**Phase 1 (단기)**: 고양이 스타일 강화
- 행동 묘사 증가 (하품, 돌아섬, 우다다, 꼬리...)
- 츤데레/경계/신뢰 반응 일관성
- 한국어 전용
- **측정**: CatScore 평균 상승 (목표: +15점 이상)

**Phase 2 (중기)**: CareProfile 반영
- 키운 방식에 따른 성격 분화
- Control에 CareProfile 포함
- **측정**: 같은 상황에서 CareProfile별 응답 차이 확인

### 실행 계획

#### Step 1: 베이스 모델 선정
```
현재 벤치마크 결과 기준으로:
- CatScore 상위 모델
- 응답 속도 적절
- 한국어 자연스러움
→ aya:8b 또는 qwen2.5:7b 중 선택
```

#### Step 2: 학습 데이터 생성 (DevTools 확장)
```
현재 DatasetGenerator 기반으로:
- SlimControl + UserText + Response 조합
- 행동 묘사 강제 포함 (템플릿에 Action 슬롯)
- TrustTier별 응답 톤 분리

1차 목표: 500개 (빠른 검증)
2차 목표: 2000개 (본격 학습)
```

#### Step 3: Unsloth 학습 환경 구축
```bash
# 필요 환경
- Python 3.10+
- CUDA (GPU 학습용)
- Unsloth 라이브러리

# 학습 파라미터 (초기값)
- LoRA rank: 16~32
- Learning rate: 2e-4
- Epochs: 3~5
- Batch size: 4 (VRAM 따라 조정)
```

#### Step 4: 학습 후 검증
```
1. 학습된 모델 Ollama에 등록
2. DevTools 벤치마크 실행 (동일 테스트셋)
3. 점수 비교:
   - CatScore 평균
   - 특히 Routine, Trust, Action 점수
4. 상세 Export로 케이스별 개선 확인
```

### 데이터 품질 규칙 (중요)

| 규칙 | 이유 |
|------|------|
| assistant 응답에 행동 묘사 1개 이상 | ActionScore 학습 |
| TrustLow → 애교 표현 금지 | 일관성 |
| TrustHigh → 거리두기 최소화 | 일관성 |
| FeedingWindow → 음식 집착 강조 | Routine 학습 |
| Afternoon → 졸림/무심 톤 | Routine 학습 |
| 응답 길이 20~80자 | 간결함 유지 |

### 즉시 실행 체크리스트

- [ ] 베이스 모델 최종 선정 (벤치마크 결과 기반)
- [ ] DatasetGenerator에 "학습용 데이터 생성" 모드 추가
- [ ] 행동 묘사 템플릿 테이블 작성
- [ ] 500개 학습 데이터 생성
- [ ] Unsloth 환경 구축 (Python)
- [ ] 1차 LoRA 학습 실행
- [ ] 학습 모델 벤치마크 비교

### 폴더 구조 (예정)

```
Tools/
├── LoRA/
│   ├── train_lora.py          # Unsloth 학습 스크립트
│   ├── convert_to_gguf.py     # GGUF 변환
│   ├── requirements.txt
│   └── configs/
│       └── cattalk_lora.yaml  # 학습 설정
│
LoraData/
├── training_data.jsonl        # 학습 데이터
├── training_data_v2.jsonl     # 확장 버전
├── test_set.jsonl             # 테스트셋 (기존)
└── action_templates.json      # 행동 묘사 템플릿
```

### 주의사항

1. **데이터 > 파라미터**: 학습 설정보다 데이터 품질이 더 중요
2. **작게 시작**: 500개로 먼저 효과 확인 후 확장
3. **벤치마크 필수**: 감으로 판단하지 말고 점수로 비교
4. **버전 관리**: 학습 데이터/모델 버전 기록 필수
